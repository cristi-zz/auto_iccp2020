{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1026d63d",
   "metadata": {},
   "source": [
    "### Network setup and training conditions\n",
    "\n",
    "In this notebook we show how the models were built and trained. All settings except:\n",
    "\n",
    " - data source (reduced data quality + number of features)\n",
    " - number of training epochs\n",
    " \n",
    " are identical with those presented in the paper. Running this notebook will not yield the performance numbers presented in the paper because the beefy networks require larger variation in the data.\n",
    " \n",
    " The AttA3 network would probably require few days to train so running it with full epoch count is not advisable if one wants a quick look at the models.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35198126",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from fastai.data.transforms import TfmdLists, DataLoaders\n",
    "import fastai.learner\n",
    "import fastai.callback.schedule\n",
    "import fastai.callback.tracker\n",
    "import fastai.basics\n",
    "import fastai.losses\n",
    "\n",
    "\n",
    "import network_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c19a327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data volumes: Train: 7255, Validation: 1073\n"
     ]
    }
   ],
   "source": [
    "data_load_path = Path(\"../data_sample\")\n",
    "train_data = np.load(data_load_path / \"train_samples.npy\")\n",
    "valid_data = np.load(data_load_path / \"valid_samples.npy\")\n",
    "train_samples = list(train_data)  # to match the requirements of fastai.TfmdLists\n",
    "valid_samples = list(valid_data)\n",
    "\n",
    "sample_length = train_data[0].shape[0]\n",
    "# Settings to match the paper experiments. Except the number of columns, all the settings are the same.\n",
    "future_length = 60\n",
    "past_length = sample_length - future_length\n",
    "no_features = train_data[0].shape[1]\n",
    "known_column_indexes = list(range(no_features))  # [0, 1, 2, 3]\n",
    "command_indexes = [2]\n",
    "target_indexes = [3]\n",
    "feature_groups = [(0, 1, 3)]\n",
    "average_range = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "feature_itemizer = network_definitions.FeatureItemizer(future_length, known_column_indexes,\n",
    "                                         command_indexes, target_indexes, feature_groups, average_range)\n",
    "tls_train = TfmdLists(train_samples, [feature_itemizer])\n",
    "tls_valid = TfmdLists(valid_samples, [feature_itemizer])\n",
    "data_dloader = DataLoaders.from_dsets(tls_train, tls_valid, bs=batch_size, drop_last=True, shuffle=True, num_workers=0, device=torch.device(\"cuda\"))\n",
    "print(f\"Data volumes: Train: {len(train_samples)}, Validation: {len(valid_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f30ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DAffAffGau():\n",
    "    model = network_definitions.ConstructDelayNet(no_features, len(command_indexes), len(target_indexes), past_length, future_length,\n",
    "                                                 filter_low_classname=\"AffineTransform\", filter_low_filter_count=4, filter_low_one_kernel_per_feature=True,\n",
    "                                                 aggregator_low_expansion=1, aggregator_low_layers=2, aggregator_low_out_bottleneck=8,\n",
    "                                                 temporal_contractor_classname=\"AffineTransform\",\n",
    "                                                 filter_high_classname=\"GaussFilter\", filter_high_filter_count=8, filter_high_one_kernel_per_feature=True, \n",
    "                                                 aggregator_high_expansion=1, aggregator_high_layers=2)\n",
    "    return model\n",
    "\n",
    "def get_DLogAffGau():\n",
    "    model = network_definitions.ConstructDelayNet(no_features, len(command_indexes), len(target_indexes), past_length, future_length,\n",
    "                                                 filter_low_classname=\"LogGauss\", filter_low_filter_count=4, filter_low_one_kernel_per_feature=True,\n",
    "                                                 aggregator_low_expansion=1, aggregator_low_layers=8, aggregator_low_out_bottleneck=8,\n",
    "                                                 temporal_contractor_classname=\"AffineTransform\",\n",
    "                                                 filter_high_classname=\"GaussFilter\", filter_high_filter_count=8, filter_high_one_kernel_per_feature=True, \n",
    "                                                 aggregator_high_expansion=1, aggregator_high_layers=2)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_AttA1():\n",
    "    model = network_definitions.ICCP_Wrap_AttentionModel(no_features, len(command_indexes), len(target_indexes), past_length, future_length,\n",
    "                                                         hidden_size=8, num_layers=4, dropout=0.35)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_AttA3():\n",
    "    model = network_definitions.ICCP_Wrap_AttentionModel(no_features, len(command_indexes), len(target_indexes), past_length, future_length,\n",
    "                                                         hidden_size=512, num_layers=4, dropout=0.35)\n",
    "    return model\n",
    "\n",
    "\n",
    "def instantiate_learner(model, data_loader):\n",
    "    learner = fastai.learner.Learner(data_loader, model, loss_func=fastai.losses.L1LossFlat(),\n",
    "                     cbs=[fastai.callback.tracker.ReduceLROnPlateau(patience=20, factor=5),\n",
    "                          fastai.callback.tracker.EarlyStoppingCallback(patience=150),\n",
    "                          fastai.callback.tracker.SaveModelCallback(fname=\"best_model_full\"),\n",
    "                          fastai.callback.tracker.TerminateOnNaNCallback(),\n",
    "                          fastai.callback.progress.CSVLogger(\"learning_progress.csv\", append=False)\n",
    "                           ],)\n",
    "    return learner\n",
    "\n",
    "def evaluate_learner(crt_learner, samples):\n",
    "    raw_preds, raw_targets = crt_learner.get_preds()\n",
    "    eval_itemset_arr = np.array(samples)\n",
    "    feature_itemizer = crt_learner.dls[0].fs[0]\n",
    "    future_temp_pred_transf = network_definitions.decode_predictions_from_the_network(raw_preds, eval_itemset_arr, feature_itemizer)\n",
    "    future_temp_target_transf = network_definitions.decode_predictions_from_the_network(raw_targets, eval_itemset_arr, feature_itemizer)\n",
    "    mae = np.average(np.abs(future_temp_target_transf[:, -future_length:] - future_temp_pred_transf[:, -future_length:]))\n",
    "    mae_wrt_to_time = np.average(np.abs(future_temp_target_transf[:, -future_length:] - future_temp_pred_transf[:, -future_length:]), axis=0)\n",
    "    return mae, mae_wrt_to_time, future_temp_pred_transf, future_temp_target_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9a5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "learners = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfaf3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup in paper\n",
    "# global_lr_rate = 1e-3\n",
    "# global_no_max_epochs = 1000\n",
    "\n",
    "# Experimental setup here, for demonstration\n",
    "global_lr_rate = 1e-3\n",
    "global_no_max_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc24fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.01781485415995121.\n",
      "Better model found at epoch 1 with valid_loss value: 0.010210155509412289.\n",
      "Better model found at epoch 2 with valid_loss value: 0.009016791358590126.\n"
     ]
    }
   ],
   "source": [
    "DAffAffGau_learner = instantiate_learner(get_DAffAffGau(), data_dloader)\n",
    "DAffAffGau_learner.fit_one_cycle(global_no_max_epochs, global_lr_rate)\n",
    "model_names.append(\"DAffAffGau\")\n",
    "learners.append(DAffAffGau_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacf82d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.088862</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.0888623520731926.\n",
      "Better model found at epoch 1 with valid_loss value: 0.023762168362736702.\n",
      "Better model found at epoch 2 with valid_loss value: 0.007523125037550926.\n"
     ]
    }
   ],
   "source": [
    "DLogAffGau_learner = instantiate_learner(get_DLogAffGau(), data_dloader)\n",
    "DLogAffGau_learner.fit_one_cycle(global_no_max_epochs, global_lr_rate)\n",
    "model_names.append(\"DLogAffGau\")\n",
    "learners.append(DLogAffGau_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca255a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.00978886429220438.\n"
     ]
    }
   ],
   "source": [
    "AttA1_learner = instantiate_learner(get_AttA1(), data_dloader)\n",
    "AttA1_learner.fit_one_cycle(global_no_max_epochs, global_lr_rate)\n",
    "model_names.append(\"AttA1\")\n",
    "learners.append(AttA1_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b95963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.008381090126931667.\n",
      "Better model found at epoch 1 with valid_loss value: 0.006417920347303152.\n"
     ]
    }
   ],
   "source": [
    "AttA3_learner = instantiate_learner(get_AttA3(), data_dloader)\n",
    "AttA3_learner.fit_one_cycle(global_no_max_epochs, global_lr_rate)\n",
    "model_names.append(\"AttA3\")\n",
    "learners.append(AttA3_learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe964fbe",
   "metadata": {},
   "source": [
    "### Network summary.\n",
    "\n",
    "Note where the bulk of parameters is concentrated in each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a800801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture for DAffAffGau:\n",
      "<class 'network_definitions.ConstructDelayNet'> with 12049 parameters:\n",
      "      <class 'network_definitions.BankedFilters'> with 64 parameters:\n",
      "      Parameters: 64\n",
      "      ------------------\n",
      "      <class 'network_definitions.FeatureAggregationStack'> with 664 parameters:\n",
      "      Parameters: 664\n",
      "      ------------------\n",
      "      <class 'network_definitions.AffineTransform'> with 32 parameters:\n",
      "      Parameters: 32\n",
      "      ------------------\n",
      "      <class 'network_definitions.BankedFilters'> with 776 parameters:\n",
      "      Parameters: 776\n",
      "      ------------------\n",
      "      <class 'network_definitions.FeatureAggregationStack'> with 10513 parameters:\n",
      "      Parameters: 10513\n",
      "      ------------------\n",
      "Parameters: 12049\n",
      "------------------\n",
      "Architecture for DLogAffGau:\n",
      "<class 'network_definitions.ConstructDelayNet'> with 13681 parameters:\n",
      "      <class 'network_definitions.BankedFilters'> with 64 parameters:\n",
      "      Parameters: 64\n",
      "      ------------------\n",
      "      <class 'network_definitions.FeatureAggregationStack'> with 2296 parameters:\n",
      "      Parameters: 2296\n",
      "      ------------------\n",
      "      <class 'network_definitions.AffineTransform'> with 32 parameters:\n",
      "      Parameters: 32\n",
      "      ------------------\n",
      "      <class 'network_definitions.BankedFilters'> with 776 parameters:\n",
      "      Parameters: 776\n",
      "      ------------------\n",
      "      <class 'network_definitions.FeatureAggregationStack'> with 10513 parameters:\n",
      "      Parameters: 10513\n",
      "      ------------------\n",
      "Parameters: 13681\n",
      "------------------\n",
      "Architecture for AttA1:\n",
      "<class 'network_definitions.ICCP_Wrap_AttentionModel'> with 8105 parameters:\n",
      "      <class 'network_definitions.AttentionModel'> with 8105 parameters:\n",
      "      Parameters: 8105\n",
      "      ------------------\n",
      "Parameters: 8105\n",
      "------------------\n",
      "Architecture for AttA3:\n",
      "<class 'network_definitions.ICCP_Wrap_AttentionModel'> with 16239929 parameters:\n",
      "      <class 'network_definitions.AttentionModel'> with 16239929 parameters:\n",
      "      Parameters: 16239929\n",
      "      ------------------\n",
      "Parameters: 16239929\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(learners)):\n",
    "    print(f\"Architecture for {model_names[k]}:\")\n",
    "    network_definitions.print_model_weights_rec(learners[k].model, max_level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d99d1a",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "\n",
    "There is no expectation that these numbers will match the paper's results. The networks are identical but the data quality is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738069f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of DAffAffGau: MAE: 0.1356\n",
      "Performance of DLogAffGau: MAE: 0.1133\n",
      "Performance of AttA1: MAE: 0.1457\n",
      "Performance of AttA3: MAE: 0.09819\n",
      "Performance of Zero: MAE: 0.1366\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "maes_timewise = []\n",
    "predictions = []\n",
    "\n",
    "for l in learners:\n",
    "    mae, mae_t, scaled_preds, scaled_targets = evaluate_learner(l, valid_samples)\n",
    "    maes.append(mae)\n",
    "    maes_timewise.append(mae_t)\n",
    "    predictions.append(scaled_preds)\n",
    "    \n",
    "# Adding \"zero\" predictor\n",
    "raw_preds, raw_targets = learners[0].get_preds()    \n",
    "zero_preds =  torch.zeros_like(raw_preds)\n",
    "eval_itemset_arr = np.array(valid_samples)\n",
    "feature_itemizer = learners[0].dls[0].fs[0]\n",
    "zero_transf = network_definitions.decode_predictions_from_the_network(zero_preds, eval_itemset_arr, feature_itemizer)\n",
    "mae_zero = np.average(np.abs(scaled_targets[:, -future_length:] - zero_transf[:, -future_length:]))\n",
    "mae_zero_time = np.average(np.abs(scaled_targets[:, -future_length:] - zero_transf[:, -future_length:]), axis=0)\n",
    "model_names.append(\"Zero\")\n",
    "maes.append(mae_zero)\n",
    "maes_timewise.append(mae_zero_time)\n",
    "predictions.append(zero_transf)\n",
    "model_names = model_names[:len(learners)+1] # just to make sure that on re-runs the Zero is not added more times than needed\n",
    "for k in range(len(model_names)):\n",
    "    print(f\"Performance of {model_names[k]}: MAE: {maes[k]:.4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
